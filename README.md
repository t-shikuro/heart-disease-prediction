# Classifying Heart Disease

For entire analysis and code see [Jupyter Notebook](https://t-shikuro.github.io/heart-disease-prediction/)

![](images/heart.gif)

### Predicting heart disease ðŸšœ

This notebook will introduce some foundation machine learning and data science concepts by exploring the problem of heart disease classification.


 The project focuses heavily on data preparation and cleaning (missing values, structuring datatypes, and textual columns). It is also time-series based where DataFrame data manipulation can be managed for advancing towards data modelling. As detailed in the following paragraphs, the training data preceeds 2012, validation data selected from 01/2012 - 04/2012, and the final testing data on 05/2012 - 11/2012.

-- Project Status: [Near-Completion]
Project Objective

How well can a prediction be made on the future sale price of a bulldozer, given its characteristics and previous examples of how much similar bulldozers were sold for?

Note: The goal for most regression evaluation metrics is to minimize the error. For example, the goal for this project will be to build a machine learning model which minimises RMSLE.

Data

The data is downloaded from the Kaggle Bluebook for Bulldozers competition: https://www.kaggle.com/c/bluebook-for-bulldozers/data

There are 3 main datasets:

Train.csv is the training set, which contains data through the end of 2011.
Valid.csv is the validation set, which contains data from January 1, 2012 - April 30, 2012 You make predictions on this set throughout the majority of the competition. Your score on this set is used to create the public leaderboard.
Test.csv is the test set, which won't be released until the last week of the competition. It contains data from May 1, 2012 - November 2012. Your score on the test set determines your final rank for the competition.
For more on the evaluation of this project check: https://www.kaggle.com/c/bluebook-for-bulldozers/overview/evaluation
4. Features

Kaggle provides a data dictionary detailing all of the features of the dataset. It can be viewed on Google Sheets: https://docs.google.com/spreadsheets/d/18ly-bLR8sbDJLITkWG7ozKm8l3RyieQ2Fpgix-beSYI/edit?usp=sharing

Methods Used
Python libraries - numpy, pandas
Machine Learning - sklearn, RandomForestRegressor(), XgBoost()
Data Visualization - matplotlib, seaborn
Evaluation Metrics - RMSLE, MAE, R2
etc.
Technologies
Python
Pandas, jupyter
XgBoost, SciKitLearn
Project Description

--

Needs of this project

data exploration/descriptive statistics
data processing/cleaning
statistical modeling
writeup/reporting
Getting Started

Clone this repo (for help see this tutorial).
Raw Data is being kept here within this repo. Alternatively, go into the cloned project folder and switch into the data directory using cd data. Due to size restrictions on GitHub, the data will need to be downloaded.
Download the data files from [Kaggle] https://www.kaggle.com/c/bluebook-for-bulldozers/data into the 'data' directory.
Extract all of the .zip files you downloaded.
Remove all the zip files by running rm *.zip.
Switch back into the bulldozer-prediction directory using cd ...

If using offline data mention that and how they may obtain the data from the froup)

Data processing/transformation scripts are being kept here

etc...
If your project is well underway and setup is fairly complicated (ie. requires installation of many packages) create another "setup.md" file and link to it here

Follow setup instructions
Featured Notebooks/Analysis/Deliverables

Notebook/Markdown/Slide Deck Title
Notebook/Markdown/Slide DeckTitle
Blog Post
RESULTS:

(Contacts) : TED SHIKURO(@slackHandle)isease-prediction
